{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import AutoTokenizer\n",
    "from datasets import load_dataset\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set a seed for reproduceability\n",
    "seed = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear model: MLPs, Weight Tieing, and batch size\n",
    "\n",
    "In this notebook, we explore what happens if we turn the final lm_head output layer into a couple of MLP layers, keeping the parameter count around 50M. We also add some complexity to the training loop such as batch size and warmup steps.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Tokenizer\n",
    "\n",
    "# 512 is a good minimal context length in principle large enough to understand paragraphs\n",
    "context_length = 512\n",
    "\n",
    "# The original Llama 2 tokenizer is available from Huggingface, but we will use the more\n",
    "# up-to-date Cosmo2 toenizer provided by Huggingface for the Llama-like SmolLM models\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"HuggingFaceTB/cosmo2-tokenizer\")\n",
    "tokenizer.model_max_length = context_length\n",
    "# There are times we need to pad.  We will make the padding token the same one that \n",
    "# signals end of sentance.\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91cc3f1752654994bc43f564ec87d650",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/104 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f525f503e8a449cb34eba61f8266b19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/104 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set dataset\n",
    "\n",
    "# Set batch size\n",
    "batch_size = 8\n",
    "\n",
    "# Load dataset from hugging face in streaming mode.\n",
    "dataset = load_dataset(\"HuggingFaceTB/smollm-corpus\", \"cosmopedia-v2\", split=\"train\", streaming=True)\n",
    "\n",
    "# Create a tokenize fundtion.\n",
    "def tokenize(item):\n",
    "    x = tokenizer(\n",
    "        item['text'],\n",
    "        truncation=True,\n",
    "        padding=True,\n",
    "        max_length=context_length,\n",
    "        return_tensors=\"pt\",\n",
    "    )\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "tokenized_dataset = dataset.map(\n",
    "    tokenize, batched=True, remove_columns=dataset.column_names\n",
    ")\n",
    "train_dl = DataLoader(dataset=tokenized_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building linear model\n",
    "\n",
    "Now let's make a linear model using a couple of back to back MLPs with Relu activation functions to explore if this is superior to just the embedding layer with linear output, assuming parameters are fixed to roughly 50M parameters.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will inherit from Pytorch's Module class\n",
    "class LinearModel(nn.Module):\n",
    "    def __init__(self, vocab_size: int, n_embed: int):\n",
    "        super().__init__()\n",
    "\n",
    "        # Map tokens to embedding space with dimension n_embed\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim=n_embed)\n",
    "\n",
    "        self.ln1 = nn.LayerNorm(n_embed)\n",
    "        self.ln2 = nn.LayerNorm(n_embed)\n",
    "\n",
    "        self.fft1 = nn.Sequential(nn.Linear(n_embed, 4*n_embed),\n",
    "                                 nn.ReLU(),\n",
    "                                 nn.Linear(4*n_embed, n_embed))\n",
    "        \n",
    "        self.fft2 = nn.Sequential(nn.Linear(n_embed, 4*n_embed),\n",
    "                                 nn.ReLU(),\n",
    "                                nn.Linear(4*n_embed, n_embed))\n",
    "                               \n",
    "\n",
    "        # Now map back to make prediction for next tokens, called logits.  The layer that\n",
    "        # does this is traditionally a linear layer called the lannguage model head.\n",
    "        self.lm_head = nn.Linear(n_embed, vocab_size, bias=False)\n",
    "        self.embedding.weight = self.lm_head.weight\n",
    "        \n",
    "\n",
    "    # Pytorch Modules have a forward method that is what is executed when the model is called\n",
    "    # The input is the (batch, tokens) tensor and a (batch, logits) tensor is returned\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.embedding(x)\n",
    "        x = x + self.fft1(self.ln1(x))\n",
    "        x = x + self.fft2(self.ln2(x))\n",
    "        logits = self.lm_head(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51.981696\n"
     ]
    }
   ],
   "source": [
    "# Let's create the model\n",
    "model = LinearModel(vocab_size = tokenizer.vocab_size, n_embed=832)\n",
    "\n",
    "# Let's see how many parameters we have\n",
    "print (sum([p.numel() for p in model.parameters()])/1.0e6)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Training Loop\n",
    "\n",
    "Let's add the batch size to be 250k tokens.  Like Smallest Llama models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This model has 51.98M  params\n",
      "The vocab size is 49152, meaning the initial loss should be ~10.803\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object of type 'float' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 43\u001b[0m\n\u001b[1;32m     39\u001b[0m     acc_step \u001b[38;5;241m=\u001b[39m (step \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m accum_iter\n\u001b[1;32m     40\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (acc_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m100\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     41\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m     42\u001b[0m             \u001b[38;5;66;03m#f\"Step: {acc_step:>5d},  Tokens:{batch_size*context_length*accum_iter*acc_step/1.0e6:>7.3f}M,  Loss: {losses[-1]:>7.3f}, Perplexity:  {math.exp(losses[-1]):>7.1f}\"\u001b[39;00m\n\u001b[0;32m---> 43\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStep: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00macc_step\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m>5d\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m,  Tokens:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbatch_size\u001b[38;5;241m*\u001b[39mcontext_length\u001b[38;5;241m*\u001b[39maccum_iter\u001b[38;5;241m*\u001b[39macc_step\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m1.0e6\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m>7.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124mM, Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlosses[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m>7.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Loss_ave: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28msum\u001b[39m(losses[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m100\u001b[39m:])\u001b[38;5;241m/\u001b[39m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43msum\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mlosses\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m>7.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Perplexity:  \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmath\u001b[38;5;241m.\u001b[39mexp(losses[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m>7.1f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     44\u001b[0m         )\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (step \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m25000\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     46\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'float' has no len()"
     ]
    }
   ],
   "source": [
    "device = \"mps\"\n",
    "model = model.to(device)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4)\n",
    "accum_iter = 128 // batch_size\n",
    "\n",
    "num_params = sum([p.numel() for p in model.parameters()]) / 1.0e6\n",
    "print(f\"This model has {num_params:.2f}M  params\")\n",
    "print(\n",
    "    f\"The vocab size is {tokenizer.vocab_size}, meaning the initial loss should be ~{math.log(tokenizer.vocab_size):.3f}\"\n",
    ")\n",
    "model.train()\n",
    "step_losses = []\n",
    "losses = []\n",
    "for step, batch in enumerate(train_dl):\n",
    "\n",
    "    # Get data\n",
    "    x = batch[\"input_ids\"].to(device)\n",
    "    att_mask = batch[\"attention_mask\"].to(device)\n",
    "\n",
    "    # Compute prediction error\n",
    "    logits = model(x)\n",
    "\n",
    "    # Shift to compare loss correctly\n",
    "    shifted_logits = logits[:, :-1].contiguous()\n",
    "    labels = x[:, 1:].contiguous()\n",
    "    loss = loss_fn(shifted_logits.view(-1, shifted_logits.size(-1)), labels.view(-1))\n",
    "    loss = loss / accum_iter\n",
    "\n",
    "    # Backpropagation\n",
    "    loss.backward()\n",
    "    step_losses.append(loss.item())\n",
    "\n",
    "    if (step + 1) % accum_iter == 0:\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        losses.append(sum(step_losses[-accum_iter:]))\n",
    "\n",
    "        acc_step = (step + 1) // accum_iter\n",
    "        if (acc_step - 1) % 100 == 0:\n",
    "            print(\n",
    "                #f\"Step: {acc_step:>5d},  Tokens:{batch_size*context_length*accum_iter*acc_step/1.0e6:>7.3f}M,  Loss: {losses[-1]:>7.3f}, Perplexity:  {math.exp(losses[-1]):>7.1f}\"\n",
    "                f\"Step: {acc_step:>5d},  Tokens:{batch_size*context_length*accum_iter*acc_step/1.0e6:>7.3f}M, Loss: {losses[-1]:>7.3f}, Loss_ave: {sum(losses[-100:])/len(losses[-100:]):>7.3f}, Perplexity:  {math.exp(losses[-1]):>7.1f}\"\n",
    "            )\n",
    "    if (step + 1) % 25000 == 0:\n",
    "        break\n",
    "    # Step:   501,  Tokens: 32.834M,  Loss:   6.160, Perplexity:    473.4\n",
    "    # Step:  1001,  Tokens: 65.602M,  Loss:   5.130, Perplexity:    169.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x13de92f60>]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input ids for king is [644]\n",
      "Top 25 closest tokens to king by cosine similarity: \n",
      "Token: 44520,      approving,   Similarity: 0.1746\n",
      "Token: 16593,        reading,   Similarity: 0.1673\n",
      "Token:  2934,        inating,   Similarity: 0.1492\n",
      "Token: 21046,        tically,   Similarity: 0.1471\n",
      "Token:  2442,          erous,   Similarity: 0.1443\n",
      "Token:  1883,          aging,   Similarity: 0.1431\n",
      "Token:  6605,          dered,   Similarity: 0.1398\n",
      "Token:  8069,          orate,   Similarity: 0.1393\n",
      "Token: 14642,          mount,   Similarity: 0.1356\n",
      "Token: 43601,         rasing,   Similarity: 0.1343\n",
      "Token: 41592,          fight,   Similarity: 0.1343\n",
      "Token: 26649,         pering,   Similarity: 0.1329\n",
      "Token:  9646,         usalem,   Similarity: 0.1323\n",
      "Token: 38491,        fecture,   Similarity: 0.1313\n",
      "Token:   309,          ation,   Similarity: 0.1305\n",
      "Token:   674,          ating,   Similarity: 0.1300\n",
      "Token: 29899,       revolves,   Similarity: 0.1294\n",
      "Token: 32105,      swallowed,   Similarity: 0.1284\n",
      "Token:  6961,        holding,   Similarity: 0.1277\n",
      "Token: 15957,        leading,   Similarity: 0.1275\n",
      "Token:  6712,        usiness,   Similarity: 0.1265\n",
      "Token:  1397,          arent,   Similarity: 0.1260\n",
      "Token: 47887,          acean,   Similarity: 0.1257\n",
      "Token: 39225,          hurst,   Similarity: 0.1255\n",
      "Token:  3918,         elines,   Similarity: 0.1253\n"
     ]
    }
   ],
   "source": [
    "# Assuming the embedding layer is already trained\n",
    "layer = model.embedding.to('cpu')\n",
    "\n",
    "# Get the embedding for 'king' (e.g., assuming 'king' corresponds to token index 0)\n",
    "k = 200\n",
    "word = 'king'\n",
    "\n",
    "print (f\"Input ids for {word} is {tokenizer(word)['input_ids']}\")\n",
    "\n",
    "word_index = tokenizer(word)['input_ids'][0]\n",
    "word_embedding = layer(torch.tensor(word_index)).detach()  # Get the embedding for 'king'\n",
    "\n",
    "# Get all embeddings\n",
    "all_embeddings = layer.weight.detach()  # Extract all embeddings\n",
    "\n",
    "\n",
    "# Compute cosine similarity between 'king' and all other tokens\n",
    "cosine_similarities = F.cosine_similarity(word_embedding.unsqueeze(0), all_embeddings, dim=1)\n",
    "\n",
    "# Get the indices of the 10 most similar tokens (excluding 'king' itself)\n",
    "top_k = torch.topk(cosine_similarities, k=k+1)  # Top 11 because 'king' will be in the list\n",
    "top_k_indices = top_k.indices[top_k.indices != word_index][:k]  # Exclude 'king'\n",
    "\n",
    "\n",
    "# Print the 10 closest tokens and their similarities\n",
    "print(f\"Top 25 closest tokens to {word} by cosine similarity: \")\n",
    "ii = 0\n",
    "for idx in top_k_indices:\n",
    "    #print(idx.item())\n",
    "    idx_word = tokenizer.decode(idx.item()).replace('\\n','')\n",
    "    if len(idx_word) > 4:\n",
    "        print(f\"Token: {idx.item():5d}, {idx_word:>14s},   Similarity: {cosine_similarities[idx].item():.4f}\")\n",
    "        ii += 1\n",
    "        if ii > 24:\n",
    "            break\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 25 closest tokens to king by distance: \n",
      "Token: 32105,      swallowed,   Distance: 0.85\n",
      "Token: 39225,          hurst,   Distance: 0.86\n",
      "Token: 24948,         Studio,   Distance: 0.86\n",
      "Token: 26027,           Joan,   Distance: 0.86\n",
      "Token: 28938,         Esther,   Distance: 0.86\n",
      "Token: 14004,        melting,   Distance: 0.86\n",
      "Token:  7611,       bringing,   Distance: 0.86\n",
      "Token: 16593,        reading,   Distance: 0.86\n",
      "Token: 48489,      detainees,   Distance: 0.86\n",
      "Token: 45184,       snapping,   Distance: 0.86\n",
      "Token: 32808,        soaking,   Distance: 0.87\n",
      "Token: 43555,          deton,   Distance: 0.87\n",
      "Token: 32415,         watery,   Distance: 0.87\n",
      "Token: 22630,          Cloud,   Distance: 0.87\n",
      "Token: 40984,        walking,   Distance: 0.87\n",
      "Token: 45614,          Britt,   Distance: 0.87\n",
      "Token: 22063,       thirteen,   Distance: 0.87\n",
      "Token: 43429,        perched,   Distance: 0.87\n",
      "Token: 41592,          fight,   Distance: 0.87\n",
      "Token: 46961,         chakra,   Distance: 0.87\n",
      "Token: 15656,        listing,   Distance: 0.87\n",
      "Token: 31588,      surveying,   Distance: 0.87\n",
      "Token: 48496,         Strain,   Distance: 0.87\n",
      "Token: 34078,        doubles,   Distance: 0.87\n",
      "Token: 29075,          Civil,   Distance: 0.87\n"
     ]
    }
   ],
   "source": [
    "distances = torch.norm(all_embeddings - word_embedding, dim=1)  # Compute L2 norm (Euclidean distance)\n",
    "\n",
    "# Get the indices of the 10 closest tokens (excluding 'king' itself)\n",
    "top_k = torch.topk(-distances, k=k+1)  # Use negative distances to mimic \\\"closest\\\"\n",
    "top_k_indices = top_k.indices[top_k.indices != word_index][:k]  # Exclude 'king'\n",
    "\n",
    "# Print the 10 closest tokens and their distances\n",
    "print(f\"\\nTop 25 closest tokens to {word} by distance: \")\n",
    "ii = 0\n",
    "for idx in top_k_indices:\n",
    "    #print(idx.item())\n",
    "    idx_word = tokenizer.decode(idx.item()).replace('\\n','')\n",
    "    if len(idx_word) > 4:    \n",
    "        print(f\"Token: {idx.item():5d}, {tokenizer.decode(idx.item()).replace('\\n',''):>14s},   Distance: {distances[idx].item():.2f}\")\n",
    "        ii += 1\n",
    "        if ii > 24:\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49.211136\n"
     ]
    }
   ],
   "source": [
    "class MultiHeadedSelfAttention(nn.Module):\n",
    "    def __init__(self, n_heads: int, n_embed: int):\n",
    "        super().__init__()\n",
    "\n",
    "        assert n_embed % n_heads == 0, \"Number of heads muct divide embedding dimension\"\n",
    "        self.n_heads = n_heads\n",
    "        self.h_dim = n_embed // n_heads\n",
    "\n",
    "        self.k = nn.Linear(n_embed, n_embed)\n",
    "        self.q = nn.Linear(n_embed, n_embed)\n",
    "        self.v= nn.Linear(n_embed, n_embed)\n",
    "\n",
    "        self.proj_out= nn.Linear(n_embed, n_embed)\n",
    "\n",
    "    def forward (self, x: torch.Tensor) -> torch.Tensor:\n",
    "        B, T, C = x.shape\n",
    "\n",
    "        # (B, T, C) -> (B, T, n_heads, h_dim) -> (B, n_heads, T, h_dim)\n",
    "        q = self.q(x).view(B, T, self.n_heads, self.h_dim).transpose(1,2)\n",
    "        k = self.k(x).view(B, T, self.n_heads, self.h_dim).transpose(1,2)\n",
    "        v = self.v(x).view(B, T, self.n_heads, self.h_dim).transpose(1,2)\n",
    "\n",
    "        x = F.scaled_dot_product_attention(q, k, v, is_causal=True)\n",
    "\n",
    "        # (B, n_heads, T, h_dim) -> (B, T, n_heads, h_dim) -> (B, T, C)\n",
    "        x.transpose(1, 2).contiguous().view(B, T, C)\n",
    "\n",
    "        return self.proj_out(x)\n",
    "\n",
    "\n",
    "# We will inherit from Pytorch's Module class\n",
    "class EmbeddingModel(nn.Module):\n",
    "    def __init__(self, vocab_size: int, n_embed: int, n_heads: int):\n",
    "        super().__init__()\n",
    "\n",
    "        # Map tokens to embedding space with dimension n_embed\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim=n_embed)\n",
    "\n",
    "        self.attn = MultiHeadedSelfAttention(n_heads, n_embed)\n",
    "        \n",
    "        self.fft = nn.Sequential(nn.Linear(n_embed, 4*n_embed),\n",
    "                                 nn.ReLU(),\n",
    "                                 nn.Linear(n_embed, 4*n_embed))\n",
    "                               \n",
    "\n",
    "        # Now map back to make prediction for next tokens, called logits.  The layer that\n",
    "        # does this is traditionally a linear layer called the lannguage model head.\n",
    "        self.lm_head = nn.Linear(n_embed, vocab_size, bias=False)\n",
    "        self.embedding.weight = self.lm_head.weight\n",
    "        \n",
    "\n",
    "    # Pytorch Modules have a forward method that is what is executed when the model is called\n",
    "    # The input is the (batch, tokens) tensor and a (batch, logits) tensor is returned\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.embedding(x)\n",
    "        x = self.attn(x)\n",
    "        x = self.fft(x)\n",
    "        logits = self.lm_head(x)\n",
    "        return logits\n",
    "    \n",
    "# Let's create the model\n",
    "model = EmbeddingModel(vocab_size = tokenizer.vocab_size, n_embed=832, n_heads=13)\n",
    "\n",
    "# Let's see how many parameters we have\n",
    "print (sum([p.numel() for p in model.parameters()])/1.0e6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
