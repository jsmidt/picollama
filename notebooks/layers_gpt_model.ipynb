{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import AutoTokenizer\n",
    "from datasets import load_dataset\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set a seed for reproduceability\n",
    "seed = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear model: MLPs, Weight Tieing, and batch size\n",
    "\n",
    "In this notebook, we explore what happens if we turn the final lm_head output layer into a couple of MLP layers, keeping the parameter count around 50M. We also add some complexity to the training loop such as batch size and warmup steps.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Tokenizer\n",
    "\n",
    "# 512 is a good minimal context length in principle large enough to understand paragraphs\n",
    "context_length = 512\n",
    "\n",
    "# The original Llama 2 tokenizer is available from Huggingface, but we will use the more\n",
    "# up-to-date Cosmo2 toenizer provided by Huggingface for the Llama-like SmolLM models\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"HuggingFaceTB/cosmo2-tokenizer\")\n",
    "tokenizer.model_max_length = context_length\n",
    "# There are times we need to pad.  We will make the padding token the same one that \n",
    "# signals end of sentance.\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03d6846576894a7bb6cc803a3b6e0c3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/104 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be193218f9884408a8a9d4a0b228e03b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/104 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set dataset\n",
    "\n",
    "# Set batch size\n",
    "batch_size = 8\n",
    "\n",
    "# Load dataset from hugging face in streaming mode.\n",
    "dataset = load_dataset(\"HuggingFaceTB/smollm-corpus\", \"cosmopedia-v2\", split=\"train\", streaming=True)\n",
    "\n",
    "# Create a tokenize fundtion.\n",
    "def tokenize(item):\n",
    "    x = tokenizer(\n",
    "        item['text'],\n",
    "        truncation=True,\n",
    "        padding=True,\n",
    "        max_length=context_length,\n",
    "        return_tensors=\"pt\",\n",
    "    )\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "tokenized_dataset = dataset.map(\n",
    "    tokenize, batched=True, remove_columns=dataset.column_names\n",
    ")\n",
    "train_dl = DataLoader(dataset=tokenized_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building linear model\n",
    "\n",
    "Now let's make a linear model using a couple of back to back MLPs with Relu activation functions to explore if this is superior to just the embedding layer with linear output, assuming parameters are fixed to roughly 50M parameters.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadedSelfAttention(nn.Module):\n",
    "    def __init__(self, n_heads: int, n_embed: int, dropout: float, bias: bool):\n",
    "        super().__init__()\n",
    "\n",
    "        assert n_embed % n_heads == 0, \"Number of heads muct divide embedding dimension\"\n",
    "        self.n_heads = n_heads\n",
    "        self.h_dim = n_embed // n_heads\n",
    "        self.dropout = dropout\n",
    "\n",
    "        self.q = nn.Linear(n_embed, n_embed, bias=bias)\n",
    "        self.k = nn.Linear(n_embed, n_embed, bias=bias)\n",
    "        self.v = nn.Linear(n_embed, n_embed, bias=bias)\n",
    "\n",
    "        self.proj_out = nn.Linear(n_embed, n_embed, bias=bias)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        B, T, C = x.shape\n",
    "\n",
    "        # (B, T, C) -> (B, T, n_heads, h_dim) -> (B, n_heads, T, h_dim)\n",
    "        q = self.q(x).view(B, T, self.n_heads, self.h_dim).transpose(1, 2)\n",
    "        k = self.k(x).view(B, T, self.n_heads, self.h_dim).transpose(1, 2)\n",
    "        v = self.v(x).view(B, T, self.n_heads, self.h_dim).transpose(1, 2)\n",
    "\n",
    "        x = F.scaled_dot_product_attention(\n",
    "            q, k, v, is_causal=True, dropout_p=self.dropout\n",
    "        )\n",
    "\n",
    "        # (B, n_heads, T, h_dim) -> (B, T, n_heads, h_dim) -> (B, T, C)\n",
    "        x = x.transpose(1, 2).contiguous().view(B, T, C)\n",
    "        return self.proj_out(x)\n",
    "\n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, n_embed: int, i_embed: int, dropout: float):\n",
    "        super().__init__()\n",
    "\n",
    "        self.linear1 = nn.Linear(n_embed, i_embed)\n",
    "        self.linear2 = nn.Linear(i_embed, n_embed)\n",
    "        self.act1 = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.linear1(x)\n",
    "        x = self.act1(x)\n",
    "        x = self.linear2(x)\n",
    "\n",
    "        return self.dropout(x)\n",
    "\n",
    "\n",
    "class Block(nn.Module):\n",
    "\n",
    "    def __init__(\n",
    "        self, n_heads: int, n_embed: int, i_embed: int, dropout: float, bias: bool\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.ln_1 = nn.LayerNorm(n_embed, bias=bias)\n",
    "        self.attn = MultiHeadedSelfAttention(n_heads, n_embed, dropout, bias)\n",
    "        self.ln_2 = nn.LayerNorm(n_embed, bias=bias)\n",
    "        self.ffn = FeedForward(n_embed, i_embed, dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.attn(self.ln_1(x))\n",
    "        x = x + self.ffn(self.ln_2(x))\n",
    "        return x\n",
    "\n",
    "\n",
    "# We will inherit from Pytorch's Module class\n",
    "class LayerModel(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        vocab_size: int,\n",
    "        context_length: int,\n",
    "        n_embed: int,\n",
    "        i_embed: int,\n",
    "        n_heads: int,\n",
    "        n_layers: int,\n",
    "        dropout: float,\n",
    "        bias: bool,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        # Map tokens to embedding space with dimension n_embed\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim=n_embed)\n",
    "        self.pos_embedding = nn.Embedding(context_length, n_embed)\n",
    "\n",
    "        self.blocks = nn.ModuleList(\n",
    "                [\n",
    "                    Block(n_heads, n_embed, i_embed, dropout, bias)\n",
    "                    for _ in range(n_layers)\n",
    "                ]\n",
    "            )\n",
    "        \n",
    "        self.lnf = nn.LayerNorm(n_embed, bias=bias)\n",
    "\n",
    "        # Now map back to make prediction for next tokens, called logits.  The layer that\n",
    "        # does this is traditionally a linear layer called the lannguage model head.\n",
    "        self.lm_head = nn.Linear(n_embed, vocab_size, bias=False)\n",
    "        self.apply(self._init_weights)\n",
    "        self.embedding.weight = self.lm_head.weight\n",
    "\n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "            if module.bias is not None:\n",
    "                torch.nn.init.zeros_(module.bias)\n",
    "        elif isinstance(module, nn.Embedding):\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "\n",
    "    # Pytorch Modules have a forward method that is what is executed when the model is called\n",
    "    # The input is the (batch, tokens) tensor and a (batch, logits) tensor is returned\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        _, T = x.shape\n",
    "        pos = torch.arange(0, T, dtype=torch.long, device=x.device)\n",
    "        tok_emb = self.embedding(x)\n",
    "        pos_emb = self.pos_embedding(pos)\n",
    "        x = tok_emb + pos_emb\n",
    "        for block in self.blocks:\n",
    "            x = block(x)\n",
    "        x = self.lnf(x)\n",
    "        logits = self.lm_head(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50.30592\n"
     ]
    }
   ],
   "source": [
    "# Let's create the model\n",
    "model = LayerModel(\n",
    "    vocab_size=tokenizer.vocab_size,\n",
    "    context_length=context_length,\n",
    "    n_embed=576,\n",
    "    i_embed = 1536,\n",
    "    n_heads=9,\n",
    "    n_layers=7,\n",
    "    dropout=0.1,\n",
    "    bias=False,\n",
    ")\n",
    "\n",
    "# Let's see how many parameters we have\n",
    "print(sum([p.numel() for p in model.parameters()]) / 1.0e6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Training Loop\n",
    "\n",
    "Let's add the batch size to be 250k tokens.  Like Smallest Llama models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This model has 50.31M  params\n",
      "The vocab size is 49152, meaning the initial loss should be ~10.803\n",
      "Step:     1,  Tokens:  0.262M,  LR: 1.05e-05, Loss:  10.963, Loss_ave:  10.963, Perplexity:  57687.5\n",
      "Step:   101,  Tokens: 26.477M,  LR: 6.00e-05, Loss:   7.570, Loss_ave:   8.990, Perplexity:   1939.7\n",
      "Step:   201,  Tokens: 52.691M,  LR: 1.09e-04, Loss:   6.295, Loss_ave:   6.872, Perplexity:    542.1\n",
      "Step:   301,  Tokens: 78.905M,  LR: 1.59e-04, Loss:   5.687, Loss_ave:   5.950, Perplexity:    295.0\n",
      "Step:   401,  Tokens:105.120M,  LR: 2.08e-04, Loss:   5.284, Loss_ave:   5.462, Perplexity:    197.1\n",
      "Step:   501,  Tokens:131.334M,  LR: 2.58e-04, Loss:   4.970, Loss_ave:   5.125, Perplexity:    144.0\n",
      "Step:   601,  Tokens:157.549M,  LR: 3.07e-04, Loss:   4.643, Loss_ave:   4.828, Perplexity:    103.9\n",
      "Step:   701,  Tokens:183.763M,  LR: 3.57e-04, Loss:   4.468, Loss_ave:   4.569, Perplexity:     87.2\n",
      "Step:   801,  Tokens:209.977M,  LR: 4.06e-04, Loss:   4.190, Loss_ave:   4.328, Perplexity:     66.0\n",
      "Step:   901,  Tokens:236.192M,  LR: 4.56e-04, Loss:   4.053, Loss_ave:   4.125, Perplexity:     57.6\n",
      "Step:  1001,  Tokens:262.406M,  LR: 5.05e-04, Loss:   3.853, Loss_ave:   3.947, Perplexity:     47.2\n",
      "Step:  1101,  Tokens:288.621M,  LR: 5.55e-04, Loss:   3.697, Loss_ave:   3.779, Perplexity:     40.3\n",
      "Step:  1201,  Tokens:314.835M,  LR: 6.04e-04, Loss:   3.557, Loss_ave:   3.623, Perplexity:     35.1\n",
      "Step:  1301,  Tokens:341.049M,  LR: 6.54e-04, Loss:   3.445, Loss_ave:   3.482, Perplexity:     31.3\n",
      "Step:  1401,  Tokens:367.264M,  LR: 7.03e-04, Loss:   3.330, Loss_ave:   3.359, Perplexity:     27.9\n",
      "Step:  1501,  Tokens:393.478M,  LR: 7.53e-04, Loss:   3.217, Loss_ave:   3.263, Perplexity:     24.9\n",
      "Step:  1601,  Tokens:419.693M,  LR: 8.02e-04, Loss:   3.130, Loss_ave:   3.187, Perplexity:     22.9\n",
      "Step:  1701,  Tokens:445.907M,  LR: 8.52e-04, Loss:   3.125, Loss_ave:   3.108, Perplexity:     22.8\n",
      "Step:  1801,  Tokens:472.121M,  LR: 9.01e-04, Loss:   3.033, Loss_ave:   3.057, Perplexity:     20.8\n",
      "Step:  1901,  Tokens:498.336M,  LR: 9.51e-04, Loss:   3.022, Loss_ave:   3.012, Perplexity:     20.5\n",
      "Step:  2001,  Tokens:524.550M,  LR: 1.00e-03, Loss:   2.951, Loss_ave:   2.963, Perplexity:     19.1\n",
      "Step:  2101,  Tokens:550.765M,  LR: 1.00e-03, Loss:   2.833, Loss_ave:   2.920, Perplexity:     17.0\n",
      "Step:  2201,  Tokens:576.979M,  LR: 1.00e-03, Loss:   2.925, Loss_ave:   2.878, Perplexity:     18.6\n",
      "Step:  2301,  Tokens:603.193M,  LR: 1.00e-03, Loss:   2.838, Loss_ave:   2.844, Perplexity:     17.1\n"
     ]
    }
   ],
   "source": [
    "device = \"mps\"\n",
    "model = model.to(device)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=2e-3)\n",
    "accum_iter = 512 // batch_size\n",
    "w_steps = 2000\n",
    "scheduler = torch.optim.lr_scheduler.LinearLR(optimizer, start_factor=0.01, total_iters=w_steps)\n",
    "\n",
    "num_params = sum([p.numel() for p in model.parameters()]) / 1.0e6\n",
    "print(f\"This model has {num_params:.2f}M  params\")\n",
    "print(\n",
    "    f\"The vocab size is {tokenizer.vocab_size}, meaning the initial loss should be ~{math.log(tokenizer.vocab_size):.3f}\"\n",
    ")\n",
    "model.train()\n",
    "step_losses = []\n",
    "losses = []\n",
    "for step, batch in enumerate(train_dl):\n",
    "\n",
    "    # Get data\n",
    "    x = batch[\"input_ids\"].to(device)\n",
    "    att_mask = batch[\"attention_mask\"].to(device)\n",
    "\n",
    "    # Compute prediction error\n",
    "    logits = model(x)\n",
    "\n",
    "    # Shift to compare loss correctly\n",
    "    shifted_logits = logits[:, :-1].contiguous()\n",
    "    labels = x[:, 1:].contiguous()\n",
    "    loss = loss_fn(shifted_logits.view(-1, shifted_logits.size(-1)), labels.view(-1))\n",
    "    loss = loss / accum_iter\n",
    "\n",
    "    # Backpropagation\n",
    "    loss.backward()\n",
    "    step_losses.append(loss.item())\n",
    "\n",
    "    if (step + 1) % accum_iter == 0:\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        losses.append(sum(step_losses[-accum_iter:]))\n",
    "\n",
    "        acc_step = (step + 1) // accum_iter\n",
    "        scheduler.step()\n",
    "        NN = 200\n",
    "        if (acc_step - 1) % NN == 0:\n",
    "            print(\n",
    "                f\"Step: {acc_step:>5d},  Tokens:{batch_size*context_length*accum_iter*acc_step/1.0e6:>7.2f}M,  LR: {scheduler.get_last_lr()[-1]:.2e}, Loss: {losses[-1]:>7.3f}, Loss_ave: {sum(losses[-NN:])/len(losses[-NN:]):>7.3f}, Perplexity:  {math.exp(losses[-1]):>7.1f}\"\n",
    "            )\n",
    "            # Step:   401,  Tokens: 26.280M, Loss:   6.782, Perplexity:    882.0\n",
    "\n",
    "            # Create a checkpoint dictionary\n",
    "            checkpoint = {\n",
    "                'epoch': acc_step,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'loss': loss,\n",
    "                # Add any other relevant metrics or data you want to save\n",
    "            }\n",
    "\n",
    "            # Save the checkpoint\n",
    "            torch.save(checkpoint, f'checkpoint_{acc_step-1:04d}.pth')\n",
    "        \n",
    "    if (step + 1) % 250000 == 0:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x16964ae10>]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input ids for woman is [24626]\n",
      "Top 25 closest tokens to woman by cosine similarity: \n",
      "Token: 28774,          women,   Similarity: 0.5754\n",
      "Token: 10202,         person,   Similarity: 0.4553\n",
      "Token: 20336,          Woman,   Similarity: 0.4312\n",
      "Token: 37479,        actress,   Similarity: 0.4249\n",
      "Token: 48281,        persons,   Similarity: 0.4174\n",
      "Token: 40124,         leader,   Similarity: 0.4139\n",
      "Token: 46775,         winner,   Similarity: 0.4031\n",
      "Token: 35054,       daughter,   Similarity: 0.3968\n",
      "Token: 38881,          grave,   Similarity: 0.3932\n",
      "Token: 45547,      president,   Similarity: 0.3919\n",
      "Token: 47461,       director,   Similarity: 0.3910\n",
      "Token: 40503,         Female,   Similarity: 0.3907\n",
      "Token: 44875,       mistress,   Similarity: 0.3866\n",
      "Token: 26998,         runner,   Similarity: 0.3845\n",
      "Token: 44400,      statesman,   Similarity: 0.3778\n",
      "Token: 41820,        brother,   Similarity: 0.3768\n",
      "Token: 47492,         artist,   Similarity: 0.3684\n",
      "Token: 15025,         mother,   Similarity: 0.3675\n",
      "Token: 46191,        heroine,   Similarity: 0.3667\n",
      "Token: 32032,         female,   Similarity: 0.3648\n",
      "Token: 12801,         master,   Similarity: 0.3629\n",
      "Token: 14360,         people,   Similarity: 0.3629\n",
      "Token: 22295,         worker,   Similarity: 0.3610\n",
      "Token: 37093,        senator,   Similarity: 0.3609\n",
      "Token: 38897,      candidate,   Similarity: 0.3594\n"
     ]
    }
   ],
   "source": [
    "# Assuming the embedding layer is already trained\n",
    "layer = model.embedding.to('cpu')\n",
    "\n",
    "# Get the embedding for 'king' (e.g., assuming 'king' corresponds to token index 0)\n",
    "k = 200\n",
    "word = 'woman'\n",
    "\n",
    "print (f\"Input ids for {word} is {tokenizer(word)['input_ids']}\")\n",
    "\n",
    "word_index = tokenizer(word)['input_ids'][0]\n",
    "word_embedding = layer(torch.tensor(word_index)).detach()  # Get the embedding for 'king'\n",
    "\n",
    "# Get all embeddings\n",
    "all_embeddings = layer.weight.detach()  # Extract all embeddings\n",
    "\n",
    "\n",
    "# Compute cosine similarity between 'king' and all other tokens\n",
    "cosine_similarities = F.cosine_similarity(word_embedding.unsqueeze(0), all_embeddings, dim=1)\n",
    "\n",
    "# Get the indices of the 10 most similar tokens (excluding 'king' itself)\n",
    "top_k = torch.topk(cosine_similarities, k=k+1)  # Top 11 because 'king' will be in the list\n",
    "top_k_indices = top_k.indices[top_k.indices != word_index][:k]  # Exclude 'king'\n",
    "\n",
    "\n",
    "# Print the 10 closest tokens and their similarities\n",
    "print(f\"Top 25 closest tokens to {word} by cosine similarity: \")\n",
    "ii = 0\n",
    "for idx in top_k_indices:\n",
    "    #print(idx.item())\n",
    "    idx_word = tokenizer.decode(idx.item()).replace('\\n','')\n",
    "    if len(idx_word) > 4:\n",
    "        print(f\"Token: {idx.item():5d}, {idx_word:>14s},   Similarity: {cosine_similarities[idx].item():.4f}\")\n",
    "        ii += 1\n",
    "        if ii > 24:\n",
    "            break\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 25 closest tokens to woman by distance: \n",
      "Token: 28774,          women,   Distance: 1.21\n",
      "Token: 38881,          grave,   Distance: 1.32\n",
      "Token: 30999,          swick,   Distance: 1.33\n",
      "Token: 47461,       director,   Distance: 1.33\n",
      "Token: 46728,        printer,   Distance: 1.34\n",
      "Token: 28895,         unanim,   Distance: 1.34\n",
      "Token: 14156,          proto,   Distance: 1.34\n",
      "Token: 44875,       mistress,   Distance: 1.34\n",
      "Token: 27255,      intendent,   Distance: 1.34\n",
      "Token: 34656,         millan,   Distance: 1.35\n",
      "Token:  8436,          galax,   Distance: 1.35\n",
      "Token:  7008,          oples,   Distance: 1.35\n",
      "Token:  7859,     practition,   Distance: 1.35\n",
      "Token:     7,     <gh_stars>,   Distance: 1.35\n",
      "Token: 40849,       XXXXXXXX,   Distance: 1.35\n",
      "Token: 43920,   BooleanField,   Distance: 1.35\n",
      "Token: 31202,   PubMedGoogle,   Distance: 1.35\n",
      "Token:  6037,           harv,   Distance: 1.35\n",
      "Token:     3,    <repo_name>,   Distance: 1.36\n",
      "Token:  9391,          occas,   Distance: 1.36\n",
      "Token: 35357,        imetres,   Distance: 1.36\n",
      "Token: 19419,      caterpill,   Distance: 1.36\n",
      "Token: 36233,         ffield,   Distance: 1.36\n",
      "Token: 46151,      labourers,   Distance: 1.36\n",
      "Token: 13343,          insic,   Distance: 1.36\n"
     ]
    }
   ],
   "source": [
    "distances = torch.norm(all_embeddings - word_embedding, dim=1)  # Compute L2 norm (Euclidean distance)\n",
    "\n",
    "# Get the indices of the 10 closest tokens (excluding 'king' itself)\n",
    "top_k = torch.topk(-distances, k=k+1)  # Use negative distances to mimic \\\"closest\\\"\n",
    "top_k_indices = top_k.indices[top_k.indices != word_index][:k]  # Exclude 'king'\n",
    "\n",
    "# Print the 10 closest tokens and their distances\n",
    "print(f\"\\nTop 25 closest tokens to {word} by distance: \")\n",
    "ii = 0\n",
    "for idx in top_k_indices:\n",
    "    #print(idx.item())\n",
    "    idx_word = tokenizer.decode(idx.item()).replace('\\n','')\n",
    "    if len(idx_word) > 4:    \n",
    "        print(f\"Token: {idx.item():5d}, {tokenizer.decode(idx.item()).replace('\\n',''):>14s},   Distance: {distances[idx].item():.2f}\")\n",
    "        ii += 1\n",
    "        if ii > 24:\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
